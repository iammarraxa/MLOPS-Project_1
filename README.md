# üöó Vehicle Data Prediction ‚Äî End-to-End MLOps Project

### üî• *An intelligent, fully-automated ML system built from scratch with CI/CD, Docker, AWS, and scalable cloud infrastructure.*

---

## üåü Project Overview

This project demonstrates how to take a **machine learning model from development to deployment** using modern **MLOps practices**.
It covers everything ‚Äî data ingestion, validation, transformation, model training, evaluation, and automated deployment using AWS and GitHub Actions.

> **Goal:** Build a production-ready machine learning pipeline for vehicle data analysis and prediction, fully automated through CI/CD on AWS infrastructure.

---

## üß† Tech Stack & Tools

| Category                   | Tools / Services Used                           |
| -------------------------- | ----------------------------------------------- |
| **Language & Environment** | Python 3.10, Conda, Jupyter Notebook            |
| **Data Storage**           | MongoDB Atlas                                   |
| **ML & Data Handling**     | pandas, NumPy, scikit-learn, PyYAML             |
| **MLOps & Cloud**          | AWS (S3, EC2, IAM, ECR)                         |
| **CI/CD**                  | GitHub Actions (self-hosted runner on EC2)      |
| **Containerization**       | Docker                                          |
| **Logging & Monitoring**   | Python `logging` module                         |
| **Web Framework**          | Flask (for web UI + inference API)              |
| **Version Control**        | Git & GitHub                                    |
| **Deployment**             | AWS EC2 with Nginx proxy (optional HTTPS setup) |

---

## üß© System Architecture

```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ        Data Source           ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ     Data Ingestion (Mongo)    ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ Data Validation & Transform   ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ    Model Training & Eval      ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ   Model Registry (AWS S3)     ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ     Flask API / Web App       ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Setup & Installation

### 1Ô∏è‚É£ Create Project Template

```bash
python template.py
```

### 2Ô∏è‚É£ Setup Local Packages

Configure `setup.py` and `pyproject.toml` to handle local imports.

> Learn more: See `crashcourse.txt` for quick setup reference.

### 3Ô∏è‚É£ Create Virtual Environment

```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
```

Verify packages:

```bash
pip list
```

---

## ‚òÅÔ∏è MongoDB Atlas Integration

1. **Sign up** at [MongoDB Atlas](https://www.mongodb.com/atlas).
2. **Create a new cluster** (Free Tier M0).
3. **Add a database user** and whitelist IP `0.0.0.0/0`.
4. **Copy connection string** (Python Driver).
5. Push your dataset from Jupyter notebook (`mongoDB_demo.ipynb`).
6. Verify your collection inside the MongoDB console.

---

## üßæ Logging & Exception Handling

* Implemented structured logging via `src/logger`
* Centralized error tracking via `src/exception`
* Verified with `demo.py`

---

## üìä Data Pipeline Components

### **1. Data Ingestion**

* Connects to MongoDB
* Fetches raw data
* Converts key‚Äìvalue pairs ‚Üí Pandas DataFrame
* Saves intermediate artifacts

### **2. Data Validation**

* Checks schema consistency via `schema.yaml`
* Detects missing, null, or drifted data

### **3. Data Transformation**

* Performs scaling, encoding, and feature engineering
* Saves transformed data for reproducibility

### **4. Model Trainer**

* Trains multiple algorithms
* Tracks performance metrics
* Selects best model based on threshold

### **5. Model Evaluation & Pusher**

* Compares current and previous models
* Pushes best model to AWS S3 (`my-model-mlopsproj/model-registry/`)

---

## ‚òÅÔ∏è AWS Integration

* **S3** ‚Äî Model registry storage
* **ECR** ‚Äî Container image registry
* **EC2** ‚Äî Hosting environment (self-hosted GitHub runner)
* **IAM** ‚Äî Secure key-based access

**IAM Setup (Quick View):**

```bash
export AWS_ACCESS_KEY_ID="YOUR_ACCESS_KEY"
export AWS_SECRET_ACCESS_KEY="YOUR_SECRET_KEY"
export AWS_DEFAULT_REGION="us-east-1"
```

Bucket naming convention:

```
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
```

---

## üê≥ CI/CD & Deployment

### ‚úÖ CI (Continuous Integration)

* Triggered on push to `main`
* Builds and tags Docker image
* Pushes image to AWS ECR

### üöÄ CD (Continuous Deployment)

* Self-hosted runner on EC2 pulls the latest image
* Stops old container
* Runs new one automatically
* Exposes app on port `5000`

### GitHub Secrets

| Key                     | Description                 |
| ----------------------- | --------------------------- |
| `AWS_ACCESS_KEY_ID`     | AWS Access Key              |
| `AWS_SECRET_ACCESS_KEY` | AWS Secret Key              |
| `AWS_DEFAULT_REGION`    | AWS Region                  |
| `ECR_REPO`              | Name of your ECR repository |

---

## üåê Running the App

Once the CI/CD pipeline finishes:

1. Visit your EC2 instance‚Äôs public IP

   ```bash
   http://<ec2-public-ip>:5000/
   ```
2. Flask web interface will load.
3. For model retraining:

   ```bash
   http://<ec2-public-ip>:5000/training
   ```

---

## üõ†Ô∏è Project Highlights

‚úîÔ∏è **Modular Code Structure** ‚Äî reusable, testable, and production-ready
‚úîÔ∏è **Automated CI/CD Pipeline** ‚Äî from commit ‚Üí deployment in under a minute
‚úîÔ∏è **Cloud-Native Architecture** ‚Äî all infrastructure built on AWS
‚úîÔ∏è **Data-Driven Workflow** ‚Äî MongoDB Atlas + Pandas + PyYAML schema
‚úîÔ∏è **Scalable Deployment** ‚Äî Dockerized app on EC2 with self-hosted runner
‚úîÔ∏è **Fail-Safe Logging** ‚Äî every step traceable through logs

---

## üß≠ Directory Structure

```
‚îú‚îÄ‚îÄ .github/workflows/aws.yaml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ configuration/
‚îÇ   ‚îú‚îÄ‚îÄ data_access/
‚îÇ   ‚îú‚îÄ‚îÄ entity/
‚îÇ   ‚îú‚îÄ‚îÄ exception/
‚îÇ   ‚îú‚îÄ‚îÄ logger/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline/
‚îú‚îÄ‚îÄ notebook/
‚îÇ   ‚îú‚îÄ‚îÄ EDA_FeatureEngg.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ mongoDB_demo.ipynb
‚îú‚îÄ‚îÄ template.py
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

---

## üß™ Example Workflow Summary

| Step | Description                                           |
| ---- | ----------------------------------------------------- |
| 1    | Data fetched from MongoDB Atlas                       |
| 2    | Validation, transformation & feature engineering      |
| 3    | Model trained and saved as artifact                   |
| 4    | Model pushed to AWS S3                                |
| 5    | Docker image built & pushed to ECR                    |
| 6    | EC2 auto-deploys containerized app via GitHub Actions |

---

## üßæ Routes

| Endpoint    | Description                      |
| ----------- | -------------------------------- |
| `/`         | Home Page                        |
| `/training` | Triggers model training pipeline |

---

## üß© Future Enhancements

* Add monitoring via **Prometheus + Grafana**
* Integrate **Airflow / Kubeflow** for orchestration
* Enable **HTTPS (NGINX + Let‚Äôs Encrypt)**
* Extend multi-model support for different vehicle classes

---

## üßë‚Äçüíª Author

**Muhammad Ammar Raza**
üåê [LinkedIn](https://www.linkedin.com/in/muhammad-ammar-raza/) | üß† MLOps | Cloud | AI

---

## üí¨ Final Note

> This project is not just an ML model ‚Äî it‚Äôs a demonstration of complete **MLOps lifecycle automation**, from data to deployment.
> It showcases how real-world systems are built, automated, and scaled using modern cloud-native tools.


